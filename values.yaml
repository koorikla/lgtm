# Minio Configuration (POC Storage)
minio:
  enabled: true
  mode: standalone
  replicas: 1
  rootUser: "minio"
  rootPassword: "minio123"
  buckets:
    - name: mimir-blocks
      policy: none
      purge: false
    - name: mimir-ruler
      policy: none
      purge: false
    - name: mimir-alertmanager
      policy: none
      purge: false
    - name: loki-data
      policy: none
      purge: false
    - name: tempo-data
      policy: none
      purge: false
  persistence:
    enabled: false # Ephemeral for POC
  resources:
    requests:
      memory: 256Mi
      cpu: 100m

# Mimir Configuration
mimir-distributed:
  enabled: true
  minio:
    enabled: false
  mimir:
    structuredConfig:
      common:
        storage:
          backend: s3
          s3:
            endpoint: "grafana-stack-minio:9000"
            access_key_id: "minio"
            secret_access_key: "minio123"
            insecure: true
            bucket_name: "mimir-blocks"
      blocks_storage:
        s3:
          bucket_name: "mimir-blocks"
      ruler_storage:
        s3:
          bucket_name: "mimir-ruler"
      alertmanager_storage:
        s3:
          bucket_name: "mimir-alertmanager"


# Loki Configuration (Monolithic)
loki:
  enabled: true
  deploymentMode: SingleBinary
  loki:
    auth_enabled: false
    commonConfig:
      replication_factor: 1
    schemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: index_
            period: 24h
    storage:
      type: 's3'
      bucketNames:
        chunks: loki-data
        ruler: loki-data
        admin: loki-data
      s3:
        endpoint: http://grafana-stack-minio:9000
        accessKeyId: minio
        secretAccessKey: minio123
        s3ForcePathStyle: true
        insecure: true
  singleBinary:
    replicas: 1
  # Disable other modes
  write:
    replicas: 0
  read:
    replicas: 0
  backend:
    replicas: 0
  chunksCache:
    enabled: true
    allocatedMemory: 256
    resources:
      requests:
        cpu: 100m
        memory: 512Mi
      limits:
        memory: 600Mi

# Tempo Configuration
tempo:
  enabled: true
  service:
    extraPorts:
      - name: grpc-query
        port: 9095
        targetPort: 9095
        protocol: TCP
  tempo:
    server:
      grpc_listen_port: 9095
    storage:
      trace:
        backend: s3
        s3:
          bucket: tempo-data
          endpoint: grafana-stack-minio:9000
          access_key: minio
          secret_key: minio123
          insecure: true

# Grafana Configuration
grafana:
  enabled: true
  adminPassword: "admin"
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Mimir
          type: prometheus
          uid: mimir
          url: http://grafana-stack-mimir-gateway.monitoring.svc:80/prometheus
          # access: proxy
          isDefault: true
        - name: Loki
          type: loki
          uid: loki
          url: http://grafana-stack-loki-gateway.monitoring.svc:80
          access: proxy
        - name: Tempo
          type: tempo
          uid: tempo
          url: http://grafana-stack-tempo.monitoring.svc:3200
          access: proxy

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default

  dashboards:
    default:
      # node-exporter:
      #   gnetId: 1860
      #   revision: 37
      #   datasource: Mimir
      k8s-views-global:
        gnetId: 15757
        revision: 37
        datasource: Mimir
      k8s-views-namespaces:
        gnetId: 15758
        revision: 34
        datasource: Mimir
      k8s-views-nodes:
        gnetId: 15759
        revision: 28
        datasource: Mimir
      k8s-views-pods:
        gnetId: 15760
        revision: 29
        datasource: Mimir
      loki-logs:
        gnetId: 13639
        revision: 1
        datasource: Loki






k8s-monitoring:
  cluster:
    # -- The name for this cluster.
    # @section -- Cluster
    name: "kind"

  #
  # Global settings
  #
  global:
    # -- The specific platform for this cluster. Will enable compatibility for some platforms. Supported options: (empty) or "openshift".
    # @section -- Global Settings
    platform: ""

    # -- The Kubernetes service. Change this if your cluster DNS is configured differently than the default.
    # @section -- Global Settings
    kubernetesAPIService: ""

    # -- How frequently to scrape metrics.
    # @section -- Global Settings
    scrapeInterval: 60s

    # -- The timeout for scraping metrics.
    # @section -- Global Settings
    scrapeTimeout: 10s

    # -- The protocols to negotiate during a Prometheus metrics scrape, in order of preference.
    # @section -- Global Settings
    scrapeProtocols: ["OpenMetricsText1.0.0", "OpenMetricsText0.0.1", "PrometheusText0.0.4"]

    # -- Whether to scrape a classic histogram thatâ€™s also exposed as a native histogram.
    # @section -- Global Settings
    scrapeClassicHistograms: false

    # -- Whether to scrape native histograms.
    # @section -- Global Settings
    scrapeNativeHistograms: false

    # -- Sets the max_cache_size for every prometheus.relabel component. ([docs](https://grafana.com/docs/alloy/latest/reference/components/prometheus/prometheus.relabel/#arguments))
    # This should be at least 2x-5x your largest scrape target or samples appended rate.
    # @section -- Global Settings
    maxCacheSize: 100000

  #
  # Destinations
  #




  # -- The list of destinations where telemetry data will be sent.
  # See the [destinations documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/destinations/README.md) for more information.
  # @section -- Destinations
  destinations:
    # - name: hostedMetrics
    #   type: prometheus
    #   url: https://prometheus.example.com/api/prom/push
    #   auth:
    #     type: basic
    #     username: "my-username"
    #     password: "my-password"

    - name: mimir
      type: prometheus
      url: http://grafana-stack-mimir-gateway.monitoring.svc:80/api/v1/push

    - name: loki
      type: loki
      url: http://grafana-stack-loki-gateway.monitoring.svc:80/loki/api/v1/push
      # auth:
      #   type: basic
      #   username: "my-username"
      #   password: "my-password"
      #   tenantIdFrom: env("LOKI_TENANT_ID")

    # - name: otlpGateway
    #   type: otlp
    #   url: https://otlp.example.com:4317/v1/traces
    #   auth:
    #     type: basic
    #     username: "my-username"
    #     password: "my-password"
    #   metrics: { enabled: true }
    #   logs:    { enabled: true }
    #   traces:  { enabled: true }





  # -- A map of destinations where telemetry data will be sent. Keys will be used as the destination name.
  # See the [destinations documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/destinations/README.md) for more information.
  # @section -- Destinations
  destinationsMap: {}

  #
  # Features
  #

  # -- Cluster Monitoring enables observability and monitoring for your Kubernetes Cluster itself.
  # Requires a destination that supports metrics.
  # To see the valid options, please see the [Cluster Monitoring feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-metrics).
  # @default -- Disabled
  # @section -- Features - Cluster Metrics
  clusterMetrics:
    # -- Enable gathering Kubernetes Cluster metrics.
    # @section -- Features - Cluster Metrics
    enabled: true

    # -- The destinations where cluster metrics will be sent. If empty, all metrics-capable destinations will be used.
    # @section -- Features - Cluster Metrics
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Cluster Metrics
    # @ignored
    collector: alloy-metrics

    # To see additional options, please see the [Cluster Monitoring feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-metrics).
    opencost:
      enabled: true
      metricsSource: mimir
      opencost:
        exporter:
          defaultClusterId: "kind"
        prometheus:
          external:
            url: "http://grafana-stack-mimir-gateway.monitoring.svc:80/prometheus"

  # -- Cluster events.
  # Requires a destination that supports logs.
  # To see the valid options, please see the [Cluster Events feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-events).
  # @default -- Disabled
  # @section -- Features - Cluster Events
  clusterEvents:
    # -- Enable gathering Kubernetes Cluster events.
    # @section -- Features - Cluster Events
    enabled: true

    # -- The destinations where cluster events will be sent. If empty, all logs-capable destinations will be used.
    # @section -- Features - Cluster Events
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Cluster Events
    # @ignored
    collector: alloy-singleton

    # To see additional options, please see the [Cluster Events feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-cluster-events).

  # -- Node logs.
  # Requires a destination that supports logs.
  # To see the valid options, please see the [Node Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-node-logs).
  # @default -- Disabled
  # @section -- Features - Node Logs
  nodeLogs:
    # -- Enable gathering Kubernetes Cluster Node logs.
    # @section -- Features - Node Logs
    enabled: true

    # -- The destinations where logs will be sent. If empty, all logs-capable destinations will be used.
    # @section -- Features - Node Logs
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Node Logs
    # @ignored
    collector: alloy-logs

    # To see additional options, please see the [Node Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-node-logs).

  # -- Pod logs.
  # Requires a destination that supports logs.
  # To see the valid options, please see the [Pod Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs).
  # @default -- Disabled
  # @section -- Features - Pod Logs
  podLogs:
    # -- Enable gathering Kubernetes Pod logs.
    # @section -- Features - Pod Logs
    enabled: true

    # -- The destinations where logs will be sent. If empty, all logs-capable destinations will be used.
    # @section -- Features - Pod Logs
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Pod Logs
    # @ignored
    collector: alloy-logs

    # To see additional options, please see the [Pod Logs feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs).

  # -- Pod logs via Kubernetes API.
  # Requires a destination that supports logs.
  # To see the valid options, please see the [Pod Logs via Kubernetes API feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs-via-kubernetes-api).
  # @default -- Disabled
  # @section -- Features - Pod Logs via Kubernetes API
  podLogsViaKubernetesApi:
    # -- Enable gathering Kubernetes Pod logs.
    # @section -- Features - Pod Logs via Kubernetes API
    enabled: true

    # -- The destinations where logs will be sent. If empty, all logs-capable destinations will be used.
    # @section -- Features - Pod Logs via Kubernetes API
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Pod Logs via Kubernetes API
    # @ignored
    collector: alloy-logs

    # To see additional options, please see the [Pod Logs via Kubernetes API feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-pod-logs-via-kubernetes-api).

  # -- Application Observability.
  # Requires destinations that supports metrics, logs, and traces.
  # To see the valid options, please see the [Application Observability feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-application-observability).
  # @default -- Disabled
  # @section -- Features - Application Observability
  applicationObservability:
    # -- Enable receiving Application Observability.
    # @section -- Features - Application Observability
    enabled: false

    # -- The destinations where application data will be sent. If empty, all capable destinations will be used.
    # @section -- Features - Application Observability
    destinations: []

    # -- The receivers used for receiving application data.
    # @section -- Features - Application Observability
    receivers: {}

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Application Observability
    # @ignored
    collector: alloy-receiver

    # To see additional options, please see the [Application Observability feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-application-observability).

  # -- Auto-Instrumentation.
  # Requires destinations that supports metrics, logs, and traces.
  # To see the valid options, please see the [Auto-Instrumentation feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-auto-instrumentation).
  # @default -- Disabled
  # @section -- Features - Auto-Instrumentation
  autoInstrumentation:
    # -- Enable automatic instrumentation for applications.
    # @section -- Features - Auto-Instrumentation
    enabled: false

    # -- The destinations where application data will be sent. If empty, all capable destinations will be used.
    # @section -- Features - Auto-Instrumentation
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Auto-Instrumentation
    # @ignored
    collector: alloy-metrics

    # To see additional options, please see the [Auto-Instrumentation feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-auto-instrumentation).

  # -- Annotation Autodiscovery enables gathering metrics from Kubernetes Pods and Services discovered by special annotations.
  # Requires a destination that supports metrics.
  # To see the valid options, please see the [Annotation Autodiscovery feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-annotation-autodiscovery).
  # @default -- Disabled
  # @section -- Features - Annotation Autodiscovery
  annotationAutodiscovery:
    # -- Enable gathering metrics from Kubernetes Pods and Services discovered by special annotations.
    # @section -- Features - Annotation Autodiscovery
    enabled: true

    # -- The destinations where cluster metrics will be sent. If empty, all metrics-capable destinations will be used.
    # @section -- Features - Annotation Autodiscovery
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Annotation Autodiscovery
    # @ignored
    collector: alloy-metrics

    # To see additional options, please see the [Annotation Autodiscovery feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-annotation-autodiscovery).

  # -- Prometheus Operator Objects enables the gathering of metrics from objects like Probes, PodMonitors, and
  # ServiceMonitors. Requires a destination that supports metrics.
  # To see the valid options, please see the [Prometheus Operator Objects feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-prometheus-operator-objects).
  # @default -- Disabled
  # @section -- Features - Prometheus Operator Objects
  prometheusOperatorObjects:
    # -- Enable gathering metrics from Prometheus Operator Objects.
    # @section -- Features - Prometheus Operator Objects
    enabled: false

    # -- The destinations where metrics will be sent. If empty, all metrics-capable destinations will be used.
    # @section -- Features - Prometheus Operator Objects
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Prometheus Operator Objects
    # @ignored
    collector: alloy-metrics

    # To see additional options, please see the [Prometheus Operator Objects feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-prometheus-operator-objects).

  # -- Profiling enables gathering profiles from applications.
  # Requires a destination that supports profiles.
  # To see the valid options, please see the [Profiling feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiling).
  # @default -- Disabled
  # @section -- Features - Profiling
  profiling:
    # -- Enable gathering profiles from applications.
    # @section -- Features - Profiling
    enabled: false

    # -- The destinations where profiles will be sent. If empty, all profiles-capable destinations will be used.
    # @section -- Features - Profiling
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Profiling
    # @ignored
    collector: alloy-profiles

    # To see additional options, please see the [Profiling feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiling).

  # -- Profiles Receiver enables receiving profiles from applications.
  # Requires a destination that supports profiles.
  # To see the valid options, please see the [Profiles Receiver feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiles-receiver).
  # @default -- Disabled
  # @section -- Features - Profiles Receiver
  profilesReceiver:
    # -- Enable gathering profiles from applications.
    # @section -- Features - Profiles Receiver
    enabled: false

    # -- The destinations where profiles will be sent. If empty, all profiles-capable destinations will be used.
    # @section -- Features - Profiles Receiver
    destinations: []

    # -- Which collector to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Profiles Receiver
    # @ignored
    collector: alloy-receiver

    # To see additional options, please see the [Profiles Receiver feature documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-profiles-receiver).

  # -- Service Integrations enables gathering telemetry data for common services and applications deployed to Kubernetes.
  # To see the valid options, please see the [Service Integrations documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-integrations).
  # @default -- No integrations enabled
  # @section -- Features - Service Integrations
  integrations:
    # -- The destinations where integration metrics will be sent. If empty, all metrics-capable destinations will be used.
    # @section -- Features - Service Integrations
    destinations: []

    # -- Which collectors to assign this feature to. Do not change this unless you are sure of what you are doing.
    # @section -- Features - Service Integrations
    # @ignored
    collector: alloy-metrics

    # To see additional options, please see the [Service Integrations documentation](https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring/charts/feature-integrations).

  # Self-reporting creates a single metric and log that reports anonymized information about how this Helm chart was
  # configured. It reports features enabled, destinations types used, and alloy instances enabled. It does not report any
  # actual telemetry data, credentials or configuration, or send any data to any destination other than the ones
  # configured above.
  # @section -- Features - Self-reporting
  selfReporting:
    # -- Enable Self-reporting.
    # @section -- Features - Self-reporting
    enabled: true

    # -- The destinations where self-report metrics will be sent. If empty, all metrics-capable destinations will be used.
    # @section -- Features - Self-reporting
    destinations: []

    # -- How frequently to generate self-report metrics. This does utilize the global scrapeInterval setting.
    # @default -- 60s
    # @section -- Features - Self-reporting
    scrapeInterval: ""

  #
  # Collectors (Alloy instances)
  #

  # An Alloy instance for collecting metrics.
  # To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
  alloy-metrics:
    # -- Deploy the Alloy instance for collecting metrics.
    # @section -- Collectors - Alloy Metrics
    enabled: true

  # An Alloy instance for data sources required to be deployed on a single replica.
  # To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
  alloy-singleton:
    # -- Deploy the Alloy instance for data sources required to be deployed on a single replica.
    # @section -- Collectors - Alloy Singleton
    enabled: true


  # An Alloy instance for collecting log data.
  # To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
  alloy-logs:
    # -- Deploy the Alloy instance for collecting log data.
    # @section -- Collectors - Alloy Logs
    enabled: true
    alloy:
      clustering:
        enabled: true

  # An Alloy instance for opening receivers to collect application data.
  # To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
  alloy-receiver:
    # -- Deploy the Alloy instance for opening receivers to collect application data.
    # @section -- Collectors - Alloy Receiver
    enabled: false

    alloy:
      # -- The ports to expose for the Alloy receiver.
      # @section -- Collectors - Alloy Receiver
      extraPorts: []

    extraService:
      # -- Create an extra service for the Alloy receiver. This service will mirror the alloy-receiver service, but its
      # name can be customized to match existing application settings.
      # @section -- Collectors - Alloy Receiver
      enabled: false
      # -- The name of the extra service to create. This will result in the format `<release-name>-<name>`.
      # @section -- Collectors - Alloy Receiver
      name: alloy
      # -- If set, the full name of the extra service to create. This will result in the format `<fullname>`.
      # @section -- Collectors - Alloy Receiver
      fullname: ""

  # An Alloy instance for gathering profiles.
  # To see all valid settings, please see the [Alloy Collector documentation](https://github.com/grafana/k8s-monitoring-helm/blob/main/charts/k8s-monitoring/docs/collectors/alloy.md).
  alloy-profiles:
    # -- Deploy the Alloy instance for gathering profiles.
    # @section -- Collectors - Alloy Profiles
    enabled: false

  collectorCommon:
    # -- Settings to apply to all Alloy instances created by this Helm chart. This includes Alloy instances created by
    # enabling Tail Sampling or Service Graph Metrics.
    # @section -- Collectors - Common
    alloy: {}

  # The Alloy Operator is a Kubernetes Operator that manages Alloy instances and their lifecycle.
  # To see all valid settings, please see the [Alloy Operator documentation](https://github.com/grafana/alloy-operator/tree/main/charts/alloy-operator).
  alloy-operator:
    # -- Deploy the Alloy Operator.
    # @section -- Alloy Operator
    deploy: true

    waitForAlloyRemoval:
      # -- Utilize a Helm Hook to wait for all Alloy instances to be removed before uninstalling the Alloy Operator.
      # This ensures that all Alloy instances are properly cleaned up before the operator is removed.
      # @section -- Alloy Operator
      enabled: true

      # -- The image to use for the Helm Hook that ensures that Alloy instances are removed during uninstall.
      # @section -- Alloy Operator
      image:
        registry: ghcr.io
        repository: grafana/helm-chart-toolbox-kubectl
        tag: 0.1.2
        digest: ""
        pullPolicy: IfNotPresent
        pullSecrets: []

      # -- Annotations to apply to the Pod for the Helm Hook to wait for all Alloy instances to be removed before
      # uninstalling the Alloy Operator
      # @section -- Alloy Operator
      podAnnotations: {}

      # -- Labels to apply to the Pod for the Helm Hook to wait for all Alloy instances to be removed before uninstalling
      # the Alloy Operator
      # @section -- Alloy Operator
      podLabels:
        sidecar.istio.io/inject: "false"
        linkerd.io/inject: disabled

      # -- Default security context to apply to the container. This can also be set to `null` to remove the security
      # context entirely. Also, `runAsUser` can be set to `null` to remove it.
      # @section -- Alloy Operator
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop: ["ALL"]
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 4242
        seccompProfile:
          type: RuntimeDefault

      # -- Set the resource field for the Helm Hook that ensures that Alloy instances are removed during uninstall.
      # @section -- Alloy Operator
      resources: {}
  #      requests:
  #       cpu: 10m
  #       memory: 64Mi
  #
  #      limits:
  #       cpu: 500m
  #       memory: 128Mi

      # -- Tolerations to apply to the Helm Hook that ensures that Alloy instances are removed during uninstall.
      # @section -- Alloy Operator
      tolerations: []

      # -- Node selector to use for the Helm Hook that ensures that Alloy instances are removed during uninstall.
      # @section -- Alloy Operator
      nodeSelector:
        kubernetes.io/os: linux

  # -- Deploy additional manifest objects
  # @section -- Extra Objects
  extraObjects: []
  # - apiVersion: external-secrets.io/v1beta1
  #   kind: ExternalSecret
  #   metadata:
  #     name: prometheus-secret
  #   spec:
  #     refreshInterval: 1h
  #     secretStoreRef:
  #       kind: SecretStore
  #       name: example
  #     target:
  #       template:
  #         data:
  #           prometheus_host: "{{ .Values.externalServices.prometheus.host }}"
  #           username: "{{`{{ .username }}`}}"
  #           password: "{{`{{ .password }}`}}"
  #     dataFrom:
  #     - extract:
  #         key: mysecret











# # Alloy Configuration
# alloy:
#   alloy:
#     configMap:
#       content: |
#         // --- LOGGING SECTION ---

#         discovery.kubernetes "pods" {
#           role = "pod"
#         }

#         loki.source.kubernetes "pods" {
#           targets    = discovery.kubernetes.pods.targets
#           forward_to = [loki.write.local.receiver]
#         }

#         loki.source.kubernetes_events "example" {
#           // Only watch for events in the kube-system namespace.
#           namespaces = ["kube-system"]

#           forward_to = [loki.write.local.receiver]
#         }

#         loki.write "local" {
#           endpoint {
#             url = "http://grafana-stack-loki-gateway.monitoring.svc:80/loki/api/v1/push"
#           }
#         }



#         // --- METRICS SECTION ---

#         //  Gather metrics from ServiceMonitors and PodMonitors (Prometheus Operator CRDs)
#         prometheus.operator.servicemonitors "all" {
#           forward_to = [prometheus.remote_write.endpoint.receiver]
#         }

#         prometheus.operator.podmonitors "all" {
#           forward_to = [prometheus.remote_write.endpoint.receiver]
#         }

#         // 5. Gather metrics from Pods with specific annotations (the "classic" way)
#         // This looks for prometheus.io/scrape: "true"
#         discovery.kubernetes "annotated_pods" {
#           role = "pod"
#         }

#         discovery.relabel "annotated_pods" {
#           targets = discovery.kubernetes.annotated_pods.targets

#           rule {
#             source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_scrape"]
#             action        = "keep"
#             regex         = "true"
#           }

#           rule {
#             source_labels = ["__meta_kubernetes_pod_annotation_prometheus_io_path"]
#             action        = "replace"
#             target_label  = "__metrics_path__"
#             regex         = "(.+)"
#           }

#           rule {
#             source_labels = ["__address__", "__meta_kubernetes_pod_annotation_prometheus_io_port"]
#             action        = "replace"
#             target_label  = "__address__"
#             regex         = "([^:]+)(?::\\d+)?;(\\d+)"
#             replacement   = "$1:$2"
#           }
#         }

#         prometheus.scrape "annotated_pods" {
#           targets    = discovery.relabel.annotated_pods.output
#           forward_to = [prometheus.remote_write.endpoint.receiver]
#         }


#         prometheus.remote_write "endpoint" {
#           endpoint {
#             url = "http://grafana-stack-mimir-gateway.monitoring.svc:80/api/v1/push"
#           }
#         }
